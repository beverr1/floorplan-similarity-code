{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d89906f-fb98-464a-b76e-599b79b07113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\OneDrive - University of Glasgow\\Documents\\Project\\Edited_Data\\Oculus_Rift\\Rotational_Coloured\\Rotational_Original.jpg → Detected 18 rooms (nodes) and 59 edges\n",
      "C:\\Users\\DELL\\OneDrive - University of Glasgow\\Documents\\Project\\Edited_Data\\Oculus_Rift\\Rotational_Coloured\\RS012_map.jpg → Detected 17 rooms (nodes) and 30 edges\n",
      "Graph Edit Distance: 36.0\n",
      "Graph-based Orientation RMSE: 6.76°\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_16436\\1864108735.py:116: RuntimeWarning: All-NaN axis encountered\n",
      "  diff = np.nanmin([diff, 360 - diff], axis=0)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import math\n",
    "\n",
    "def extract_graph_from_image(image_path, min_area=40, threshold_dist=150):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # === Step 1: Detect red areas (rooms) ===\n",
    "    lower_red1 = np.array([0, 50, 30])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 50, 30])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask_red = cv2.inRange(hsv, lower_red1, upper_red1) | cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "\n",
    "    red_kernel = np.ones((3, 3), np.uint8)\n",
    "    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_CLOSE, red_kernel, iterations=0)\n",
    "\n",
    "    # === Step 2: Black line detection (refined) ===\n",
    "    mask_black_thresh = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, blockSize=11, C=5\n",
    "    )\n",
    "\n",
    "    edges_strong = cv2.Canny(gray, 30, 100)\n",
    "    edges_soft = cv2.Canny(gray, 10, 60)\n",
    "    edges = cv2.bitwise_or(edges_strong, edges_soft)\n",
    "\n",
    "    mask_black = cv2.bitwise_or(mask_black_thresh, edges)\n",
    "\n",
    "    black_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask_black = cv2.morphologyEx(mask_black, cv2.MORPH_CLOSE, black_kernel, iterations=1)\n",
    "\n",
    "    # === Step 3: Subtract black outlines from red areas ===\n",
    "    mask_cleaned = cv2.bitwise_and(mask_red, cv2.bitwise_not(mask_black))\n",
    "\n",
    "    # === Step 4: Connected components ===\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_cleaned, connectivity=8)\n",
    "\n",
    "    G = nx.Graph()\n",
    "    room_centroids = []\n",
    "\n",
    "    for i in range(1, num_labels):  # Skip background\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if area >= min_area:\n",
    "            cx, cy = centroids[i]\n",
    "            room_centroids.append((int(cx), int(cy)))\n",
    "            G.add_node(len(room_centroids) - 1, pos=(int(cx), int(cy)))\n",
    "\n",
    "    for i, (x1, y1) in enumerate(room_centroids):\n",
    "        for j, (x2, y2) in enumerate(room_centroids):\n",
    "            if i < j:\n",
    "                dist = np.linalg.norm([x1 - x2, y1 - y2])\n",
    "                if dist < threshold_dist:\n",
    "                    G.add_edge(i, j)\n",
    "\n",
    "    print(f\"{image_path} → Detected {len(G.nodes)} rooms (nodes) and {len(G.edges)} edges\")\n",
    "    return G\n",
    "\n",
    "def compute_orientation_matrix(G):\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    nodes = list(G.nodes)\n",
    "    N = len(nodes)\n",
    "    theta = np.zeros((N, N))\n",
    "\n",
    "    for i in range(N):\n",
    "        x1, y1 = pos[nodes[i]]\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                x2, y2 = pos[nodes[j]]\n",
    "                dx, dy = x2 - x1, y2 - y1\n",
    "                angle = np.degrees(np.arctan2(dy, dx)) % 360\n",
    "                theta[i, j] = angle\n",
    "            else:\n",
    "                theta[i, j] = np.nan\n",
    "    return theta\n",
    "\n",
    "def compare_orientation_matrices_with_matching(G1, G2):\n",
    "    pos1 = nx.get_node_attributes(G1, 'pos')\n",
    "    pos2 = nx.get_node_attributes(G2, 'pos')\n",
    "    nodes1 = list(G1.nodes)\n",
    "    nodes2 = list(G2.nodes)\n",
    "\n",
    "    if not pos1 or not pos2 or len(nodes1) == 0 or len(nodes2) == 0:\n",
    "        print(\"Error: One or both graphs have no nodes.\")\n",
    "        return float('nan')\n",
    "\n",
    "    coords1 = np.array([pos1[n] for n in nodes1])\n",
    "    coords2 = np.array([pos2[n] for n in nodes2])\n",
    "\n",
    "    dist_matrix = np.linalg.norm(coords1[:, None, :] - coords2[None, :, :], axis=2)\n",
    "    row_ind, col_ind = linear_sum_assignment(dist_matrix)\n",
    "\n",
    "    matched_nodes1 = [nodes1[i] for i in row_ind]\n",
    "    matched_nodes2 = [nodes2[j] for j in col_ind]\n",
    "\n",
    "    orient1 = compute_orientation_matrix(G1)\n",
    "    orient2 = compute_orientation_matrix(G2)\n",
    "\n",
    "    N = len(row_ind)\n",
    "    theta1_subset = np.full((N, N), np.nan)\n",
    "    theta2_subset = np.full((N, N), np.nan)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                theta1_subset[i, j] = orient1[matched_nodes1[i], matched_nodes1[j]]\n",
    "                theta2_subset[i, j] = orient2[matched_nodes2[i], matched_nodes2[j]]\n",
    "\n",
    "    diff = np.abs(theta1_subset - theta2_subset)\n",
    "    diff = np.nanmin([diff, 360 - diff], axis=0)\n",
    "    rmse = np.sqrt(np.nanmean(diff**2))\n",
    "    return rmse\n",
    "\n",
    "def compute_ged(G1, G2, timeout=10):\n",
    "    return nx.graph_edit_distance(G1, G2, timeout=timeout)\n",
    "\n",
    "# === Example Usage ===\n",
    "\n",
    "original_path = r #copy path of original floor plan\n",
    "sketch_path = r #copy path of sketched floor plan\n",
    "\n",
    "G_original = extract_graph_from_image(original_path)\n",
    "G_sketch = extract_graph_from_image(sketch_path)\n",
    "\n",
    "ged_score = compute_ged(G_original, G_sketch)\n",
    "rmse_score = compare_orientation_matrices_with_matching(G_original, G_sketch)\n",
    "\n",
    "print(f\"Graph Edit Distance: {ged_score}\")\n",
    "print(f\"Graph-based Orientation RMSE: {rmse_score:.2f}°\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac80b32-418e-4e32-96c0-e576847d818c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
